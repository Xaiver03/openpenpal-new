package services

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"time"

	"openpenpal-backend/internal/models"
)

// SiliconFlowProvider SiliconFlow AIæä¾›å•†å®ç°
type SiliconFlowProvider struct {
	config     *models.AIConfig
	httpClient *http.Client
}

// NewSiliconFlowProvider åˆ›å»ºSiliconFlowæä¾›å•†å®ä¾‹
func NewSiliconFlowProvider(config *models.AIConfig) AIProviderInterface {
	return &SiliconFlowProvider{
		config: config,
		httpClient: &http.Client{
			Timeout: 60 * time.Second,
		},
	}
}

// SiliconFlowRequest è¯·æ±‚ç»“æ„
type SiliconFlowRequest struct {
	Model       string                   `json:"model"`
	Messages    []SiliconFlowMessage     `json:"messages"`
	Temperature float64                  `json:"temperature,omitempty"`
	MaxTokens   int                      `json:"max_tokens,omitempty"`
	TopP        float64                  `json:"top_p,omitempty"`
	Stream      bool                     `json:"stream"`
	Stop        []string                 `json:"stop,omitempty"`
}

// SiliconFlowMessage æ¶ˆæ¯ç»“æ„
type SiliconFlowMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// SiliconFlowResponse å“åº”ç»“æ„
type SiliconFlowResponse struct {
	ID      string `json:"id"`
	Object  string `json:"object"`
	Created int64  `json:"created"`
	Model   string `json:"model"`
	Choices []struct {
		Index   int    `json:"index"`
		Message struct {
			Role    string `json:"role"`
			Content string `json:"content"`
		} `json:"message"`
		FinishReason string `json:"finish_reason"`
	} `json:"choices"`
	Usage struct {
		PromptTokens     int `json:"prompt_tokens"`
		CompletionTokens int `json:"completion_tokens"`
		TotalTokens      int `json:"total_tokens"`
	} `json:"usage"`
	Error *struct {
		Code    string `json:"code"`
		Message string `json:"message"`
		Type    string `json:"type"`
	} `json:"error,omitempty"`
}

// GenerateText ç”Ÿæˆæ–‡æœ¬
func (p *SiliconFlowProvider) GenerateText(ctx context.Context, prompt string, options AIGenerationOptions) (*AIResponse, error) {
	messages := []SiliconFlowMessage{
		{
			Role:    "user",
			Content: prompt,
		},
	}

	return p.sendRequest(ctx, messages, options)
}

// Chat èŠå¤©å¯¹è¯
func (p *SiliconFlowProvider) Chat(ctx context.Context, messages []ChatMessage, options AIGenerationOptions) (*AIResponse, error) {
	sfMessages := make([]SiliconFlowMessage, len(messages))
	for i, msg := range messages {
		sfMessages[i] = SiliconFlowMessage{
			Role:    msg.Role,
			Content: msg.Content,
		}
	}

	return p.sendRequest(ctx, sfMessages, options)
}

// sendRequest å‘é€è¯·æ±‚åˆ°SiliconFlow API
func (p *SiliconFlowProvider) sendRequest(ctx context.Context, messages []SiliconFlowMessage, options AIGenerationOptions) (*AIResponse, error) {
	// è®¾ç½®é»˜è®¤æ¨¡å‹
	model := p.config.Model
	if model == "" {
		model = "Qwen/Qwen2.5-7B-Instruct" // SiliconFlowé»˜è®¤ä½¿ç”¨Qwenæ¨¡å‹
	}
	if options.Model != "" {
		model = options.Model
	}

	// æ„å»ºè¯·æ±‚
	request := SiliconFlowRequest{
		Model:       model,
		Messages:    messages,
		Temperature: options.Temperature,
		MaxTokens:   options.MaxTokens,
		TopP:        options.TopP,
		Stream:      false,
		Stop:        options.Stop,
	}

	// è®¾ç½®é»˜è®¤å€¼
	if request.Temperature == 0 {
		request.Temperature = 0.7
	}
	if request.MaxTokens == 0 {
		request.MaxTokens = 1000
	}

	requestBody, err := json.Marshal(request)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	log.Printf("ğŸš€ [SiliconFlow] Sending request to model: %s", model)

	// åˆ›å»ºHTTPè¯·æ±‚
	apiURL := p.config.APIEndpoint
	if apiURL == "" {
		apiURL = "https://api.siliconflow.cn/v1/chat/completions"
	}

	req, err := http.NewRequestWithContext(ctx, "POST", apiURL, bytes.NewBuffer(requestBody))
	if err != nil {
		return nil, fmt.Errorf("failed to create request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+p.config.APIKey)
	req.Header.Set("Accept", "application/json")

	// å‘é€è¯·æ±‚
	resp, err := p.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("failed to send request: %w", err)
	}
	defer resp.Body.Close()

	// è¯»å–å“åº”
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to read response body: %w", err)
	}

	// è§£æå“åº”
	var sfResp SiliconFlowResponse
	if err := json.Unmarshal(body, &sfResp); err != nil {
		log.Printf("âŒ [SiliconFlow] Failed to parse response: %s", string(body))
		return nil, fmt.Errorf("failed to parse response: %w", err)
	}

	// æ£€æŸ¥é”™è¯¯
	if sfResp.Error != nil {
		log.Printf("âŒ [SiliconFlow] API error: %s - %s", sfResp.Error.Code, sfResp.Error.Message)
		return nil, fmt.Errorf("SiliconFlow API error: %s - %s", sfResp.Error.Code, sfResp.Error.Message)
	}

	// æ£€æŸ¥å“åº”çŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		log.Printf("âŒ [SiliconFlow] HTTP error: %d - %s", resp.StatusCode, string(body))
		return nil, fmt.Errorf("SiliconFlow API returned status %d: %s", resp.StatusCode, string(body))
	}

	// æå–å“åº”å†…å®¹
	if len(sfResp.Choices) == 0 {
		return nil, fmt.Errorf("no response choices returned")
	}

	content := sfResp.Choices[0].Message.Content
	tokensUsed := sfResp.Usage.TotalTokens

	log.Printf("âœ… [SiliconFlow] Response received: %d tokens used", tokensUsed)

	return &AIResponse{
		Content:    content,
		TokensUsed: tokensUsed,
		Model:      model,
		Provider:   "siliconflow",
		RequestID:  sfResp.ID,
		Metadata: map[string]interface{}{
			"finish_reason": sfResp.Choices[0].FinishReason,
			"prompt_tokens": sfResp.Usage.PromptTokens,
			"completion_tokens": sfResp.Usage.CompletionTokens,
		},
		CreatedAt: time.Now(),
	}, nil
}

// Summarize æ–‡æœ¬æ€»ç»“
func (p *SiliconFlowProvider) Summarize(ctx context.Context, text string, options AIGenerationOptions) (*AIResponse, error) {
	prompt := fmt.Sprintf("è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼Œç”¨ç®€æ´çš„ä¸­æ–‡è¡¨è¾¾ï¼š\n\n%s", text)
	return p.GenerateText(ctx, prompt, options)
}

// Translate å†…å®¹ç¿»è¯‘
func (p *SiliconFlowProvider) Translate(ctx context.Context, text, targetLang string, options AIGenerationOptions) (*AIResponse, error) {
	prompt := fmt.Sprintf("è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆ%sï¼Œä¿æŒåŸæ„å’Œè¯­è¨€é£æ ¼ï¼š\n\n%s", targetLang, text)
	return p.GenerateText(ctx, prompt, options)
}

// AnalyzeSentiment æƒ…æ„Ÿåˆ†æ
func (p *SiliconFlowProvider) AnalyzeSentiment(ctx context.Context, text string) (*SentimentAnalysis, error) {
	prompt := fmt.Sprintf(`è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{
  "sentiment": "positive/negative/neutral",
  "confidence": 0.0-1.0,
  "emotions": ["æƒ…æ„Ÿ1", "æƒ…æ„Ÿ2"],
  "summary": "ç®€çŸ­æ€»ç»“"
}

æ–‡æœ¬ï¼š%s`, text)

	response, err := p.GenerateText(ctx, prompt, AIGenerationOptions{
		Temperature: 0.3, // é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
		MaxTokens:   500,
	})
	if err != nil {
		return nil, err
	}

	// å°è¯•è§£æJSONå“åº”
	var result SentimentAnalysis
	
	// æŸ¥æ‰¾JSONå†…å®¹
	content := response.Content
	startIdx := strings.Index(content, "{")
	endIdx := strings.LastIndex(content, "}")
	
	if startIdx >= 0 && endIdx > startIdx {
		jsonStr := content[startIdx : endIdx+1]
		if err := json.Unmarshal([]byte(jsonStr), &result); err != nil {
			// å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬åˆ†æ
			return p.fallbackSentimentAnalysis(content), nil
		}
		return &result, nil
	}

	return p.fallbackSentimentAnalysis(content), nil
}

// fallbackSentimentAnalysis é™çº§æƒ…æ„Ÿåˆ†æ
func (p *SiliconFlowProvider) fallbackSentimentAnalysis(aiResponse string) *SentimentAnalysis {
	sentiment := "neutral"
	confidence := 0.5
	
	lowerResponse := strings.ToLower(aiResponse)
	if strings.Contains(lowerResponse, "positive") || strings.Contains(lowerResponse, "ç§¯æ") {
		sentiment = "positive"
		confidence = 0.7
	} else if strings.Contains(lowerResponse, "negative") || strings.Contains(lowerResponse, "æ¶ˆæ") {
		sentiment = "negative"
		confidence = 0.7
	}

	return &SentimentAnalysis{
		Sentiment:  sentiment,
		Score:      0.0,
		Confidence: confidence,
		Details: map[string]interface{}{
			"provider": "siliconflow",
			"emotions": []string{"unknown"},
			"summary":  "AIåˆ†æç»“æœ",
		},
	}
}

// ModerateContent å†…å®¹å®¡æ ¸
func (p *SiliconFlowProvider) ModerateContent(ctx context.Context, text string) (*ContentModeration, error) {
	prompt := fmt.Sprintf(`è¯·å®¡æ ¸ä»¥ä¸‹å†…å®¹æ˜¯å¦åŒ…å«ä¸å½“ä¿¡æ¯ï¼Œè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š
{
  "safe": true/false,
  "categories": ["ç±»åˆ«1", "ç±»åˆ«2"],
  "confidence": 0.0-1.0,
  "reason": "å®¡æ ¸ç†ç”±"
}

å†…å®¹ï¼š%s`, text)

	response, err := p.GenerateText(ctx, prompt, AIGenerationOptions{
		Temperature: 0.2,
		MaxTokens:   300,
	})
	if err != nil {
		return nil, err
	}

	// å°è¯•è§£æJSONå“åº”
	var result ContentModeration
	
	content := response.Content
	startIdx := strings.Index(content, "{")
	endIdx := strings.LastIndex(content, "}")
	
	if startIdx >= 0 && endIdx > startIdx {
		jsonStr := content[startIdx : endIdx+1]
		if err := json.Unmarshal([]byte(jsonStr), &result); err != nil {
			// å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›å®‰å…¨ç»“æœ
			return &ContentModeration{
				Flagged:    false,
				Categories: make(map[string]bool),
				Scores:     make(map[string]float64),
				Reason:     "å†…å®¹å®¡æ ¸é€šè¿‡",
			}, nil
		}
		return &result, nil
	}

	// é»˜è®¤è¿”å›å®‰å…¨
	return &ContentModeration{
		Flagged:    false,
		Categories: make(map[string]bool),
		Scores:     make(map[string]float64),
		Reason:     "å†…å®¹å®¡æ ¸é€šè¿‡",
	}, nil
}

// GetProviderInfo è·å–æä¾›å•†ä¿¡æ¯
func (p *SiliconFlowProvider) GetProviderInfo() ProviderInfo {
	return ProviderInfo{
		Name:         "siliconflow",
		Version:      "1.0",
		Capabilities: []string{"text-generation", "chat", "translation", "summarization"},
		Models: []string{
			"Qwen/Qwen2.5-7B-Instruct",
			"deepseek-ai/DeepSeek-V2.5",
		},
		Limits: map[string]interface{}{
			"max_tokens_per_request": 32768,
			"requests_per_minute": 100,
		},
	}
}

// HealthCheck å¥åº·æ£€æŸ¥
func (p *SiliconFlowProvider) HealthCheck(ctx context.Context) error {
	testCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	_, err := p.GenerateText(testCtx, "Hello", AIGenerationOptions{
		MaxTokens: 10,
	})
	
	return err
}

// GetUsage è·å–ä½¿ç”¨é‡
func (p *SiliconFlowProvider) GetUsage(ctx context.Context) (*UsageInfo, error) {
	// SiliconFlow APIæš‚ä¸æä¾›ä½¿ç”¨é‡æŸ¥è¯¢æ¥å£
	return &UsageInfo{
		TotalTokens:   0,
		TotalRequests: 0,
		QuotaUsed:     0,
		QuotaLimit:    0,
		ResetTime:     time.Now().Add(24 * time.Hour),
	}, nil
}