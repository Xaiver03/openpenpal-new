package services

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"math/rand"
	"openpenpal-backend/internal/config"
	"openpenpal-backend/internal/models"
	"strings"
	"time"

	"github.com/google/uuid"
	"gorm.io/gorm"
)

// UnifiedAIService ç»Ÿä¸€çš„AIæœåŠ¡ï¼Œæ•´åˆäº†æ‰€æœ‰AIåŠŸèƒ½
// é›†æˆäº†é…ç½®ç®¡ç†ã€SOTAå¢å¼ºåŠŸèƒ½å’ŒåŸæœ‰çš„AIæœåŠ¡èƒ½åŠ›
type UnifiedAIService struct {
	*EnhancedAIService          // ç»§æ‰¿SOTAå¢å¼ºåŠŸèƒ½
	configService      *ConfigService // é…ç½®æœåŠ¡
	templateCache      map[string][]models.AIContentTemplate
	cacheLastUpdated   time.Time
	cacheTTL          time.Duration
}

// NewUnifiedAIService åˆ›å»ºç»Ÿä¸€AIæœåŠ¡å®ä¾‹
func NewUnifiedAIService(db *gorm.DB, config *config.Config) *UnifiedAIService {
	// åˆ›å»ºé…ç½®æœåŠ¡
	configService := NewConfigService(db)
	
	// åˆ›å»ºå¢å¼ºAIæœåŠ¡
	enhancedService := NewEnhancedAIService(db, config)
	
	// åˆ›å»ºç»Ÿä¸€æœåŠ¡
	unifiedService := &UnifiedAIService{
		EnhancedAIService: enhancedService,
		configService:     configService,
		templateCache:     make(map[string][]models.AIContentTemplate),
		cacheTTL:         5 * time.Minute,
	}

	log.Println("âœ… [UnifiedAIService] ç»Ÿä¸€AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
	return unifiedService
}

// GetInspiration è·å–å†™ä½œçµæ„Ÿï¼ˆä½¿ç”¨é…ç½®åŒ–æ¨¡æ¿ï¼‰
func (s *UnifiedAIService) GetInspiration(ctx context.Context, req *models.AIInspirationRequest) (*models.AIInspirationResponse, error) {
	log.Printf("ğŸ¯ [UnifiedAIService] è·å–å†™ä½œçµæ„Ÿï¼Œä¸»é¢˜: %s, æ•°é‡: %d", req.Theme, req.Count)

	// è®°å½•æŒ‡æ ‡
	s.metrics.IncrementRequest()
	startTime := time.Now()

	defer func() {
		duration := time.Since(startTime)
		s.metrics.RecordResponseTime(duration)
	}()

	// å°è¯•ä»é…ç½®åŒ–æ¨¡æ¿è·å–çµæ„Ÿ
	inspirations, err := s.getInspirationsFromConfig(req)
	if err != nil {
		log.Printf("âš ï¸ [UnifiedAIService] ä»é…ç½®è·å–çµæ„Ÿå¤±è´¥ï¼Œä½¿ç”¨fallback: %v", err)
		s.metrics.IncrementFallback()
		return s.getFallbackInspiration(req), nil
	}

	// å¦‚æœé…ç½®åŒ–æ¨¡æ¿æ•°é‡ä¸è¶³ï¼Œè¡¥å……AIç”Ÿæˆçš„å†…å®¹
	if len(inspirations) < req.Count {
		log.Printf("ğŸ¤– [UnifiedAIService] é…ç½®æ¨¡æ¿ä¸è¶³ï¼Œä½¿ç”¨AIç”Ÿæˆè¡¥å……å†…å®¹")
		aiInspirations, err := s.generateAIInspirations(ctx, req)
		if err == nil && len(aiInspirations) > 0 {
			inspirations = append(inspirations, aiInspirations...)
		}
	}

	// ç¡®ä¿æ•°é‡ä¸è¶…è¿‡è¯·æ±‚
	if len(inspirations) > req.Count {
		inspirations = inspirations[:req.Count]
	}

	s.metrics.IncrementSuccess()
	
	response := &models.AIInspirationResponse{
		Inspirations: inspirations,
		Metadata: map[string]interface{}{
			"source":           "unified_config",
			"template_count":   len(inspirations),
			"generation_time":  time.Since(startTime).Milliseconds(),
			"cache_used":      s.isCacheValid(),
		},
	}

	log.Printf("âœ… [UnifiedAIService] æˆåŠŸè¿”å› %d æ¡çµæ„Ÿ", len(inspirations))
	return response, nil
}

// GenerateReply ç”ŸæˆAIå›ä¿¡ï¼ˆä½¿ç”¨é…ç½®åŒ–äººè®¾ï¼‰
func (s *UnifiedAIService) GenerateReply(ctx context.Context, req *models.AIReplyRequest) (*models.Letter, error) {
	log.Printf("ğŸ‘¤ [UnifiedAIService] ç”ŸæˆAIå›ä¿¡ï¼Œäººè®¾: %s", req.Persona)

	// è·å–äººè®¾é…ç½®
	personaConfig, err := s.configService.GetPersonaConfig(string(req.Persona))
	if err != nil {
		log.Printf("âš ï¸ [UnifiedAIService] è·å–äººè®¾é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: %v", err)
		personaConfig = s.getDefaultPersonaConfig(req.Persona)
	}

	// è·å–ç³»ç»Ÿæç¤ºè¯
	systemPrompt, err := s.configService.GetSystemPrompt("reply")
	if err != nil {
		log.Printf("âš ï¸ [UnifiedAIService] è·å–ç³»ç»Ÿæç¤ºè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: %v", err)
		systemPrompt = s.getDefaultSystemPrompt("reply")
	}

	// æ„å»ºAIæç¤ºè¯
	prompt := s.buildReplyPrompt(req, personaConfig, systemPrompt)

	// è°ƒç”¨AIç”Ÿæˆå›ä¿¡
	content, err := s.callAIProvider(ctx, prompt)
	if err != nil {
		return nil, fmt.Errorf("AIå›ä¿¡ç”Ÿæˆå¤±è´¥: %w", err)
	}

	// æ„å»ºå›ä¿¡Letterå¯¹è±¡
	reply := &models.Letter{
		ID:        uuid.New().String(),
		Title:     s.generateReplyTitle(req.OriginalLetter.Title),
		Content:   content,
		Type:      models.LetterTypeReply,
		Status:    models.LetterStatusDraft,
		Metadata: map[string]interface{}{
			"ai_generated":    true,
			"persona":         string(req.Persona),
			"original_letter": req.OriginalLetter.ID,
			"generation_time": time.Now(),
		},
		CreatedAt: time.Now(),
		UpdatedAt: time.Now(),
	}

	log.Printf("âœ… [UnifiedAIService] AIå›ä¿¡ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: %d å­—ç¬¦", len(content))
	return reply, nil
}

// MatchPenPal ç¬”å‹åŒ¹é…ï¼ˆä½¿ç”¨é…ç½®åŒ–åŒ¹é…ç®—æ³•ï¼Œæ”¯æŒç”¨æˆ·å¯æ§å»¶è¿Ÿï¼‰
func (s *UnifiedAIService) MatchPenPal(ctx context.Context, req *models.AIMatchRequest) (*models.AIMatchResponse, error) {
	log.Printf("ğŸ’Œ [UnifiedAIService] æ‰§è¡Œç¬”å‹åŒ¹é…ï¼Œä¿¡ä»¶ID: %s, å»¶è¿Ÿé€‰é¡¹: %s", req.LetterID, req.DelayOption)

	// è®¡ç®—ç”¨æˆ·é€‰æ‹©çš„å»¶è¿Ÿæ—¶é—´
	delayMinutes := s.calculateUserDelay(req.DelayOption)
	
	// è·å–åŒ¹é…ç®—æ³•é…ç½®
	matchConfig, err := s.configService.GetConfig("matching", "algorithm")
	if err != nil {
		log.Printf("âš ï¸ [UnifiedAIService] è·å–åŒ¹é…ç®—æ³•é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: %v", err)
	}

	// å¦‚æœæœ‰å»¶è¿Ÿè¦æ±‚ï¼Œä½¿ç”¨å»¶è¿Ÿé˜Ÿåˆ—
	if delayMinutes > 0 {
		log.Printf("ğŸ• [UnifiedAIService] å»¶è¿Ÿ %d åˆ†é’Ÿåæ‰§è¡ŒåŒ¹é…", delayMinutes)
		
		// åˆ›å»ºå»¶è¿Ÿä»»åŠ¡
		task := &models.DelayQueueRecord{
			ID:           uuid.New().String(),
			TaskType:     "ai_match",
			Payload:      s.marshalMatchRequest(req),
			DelayedUntil: time.Now().Add(time.Duration(delayMinutes) * time.Minute),
			Status:       "pending",
			CreatedAt:    time.Now(),
			UpdatedAt:    time.Now(),
		}
		
		// è°ƒåº¦å»¶è¿Ÿä»»åŠ¡
		if err := s.db.Create(task).Error; err != nil {
			log.Printf("âŒ [UnifiedAIService] åˆ›å»ºå»¶è¿ŸåŒ¹é…ä»»åŠ¡å¤±è´¥: %v", err)
			// é™çº§ï¼šç«‹å³æ‰§è¡ŒåŒ¹é…
			return s.performImmediateMatch(ctx, req, matchConfig)
		}
		
		// è¿”å›å¤„ç†ä¸­çŠ¶æ€
		return &models.AIMatchResponse{
			Status:  "processing",
			Message: fmt.Sprintf("æ­£åœ¨ä¸ºæ‚¨å¯»æ‰¾æœ€åˆé€‚çš„ç¬”å‹ï¼Œé¢„è®¡ %d åˆ†é’Ÿåå®ŒæˆåŒ¹é…...", delayMinutes),
			Metadata: map[string]interface{}{
				"delay_minutes": delayMinutes,
				"task_id":       task.ID,
			},
		}, nil
	}

	// ç«‹å³æ‰§è¡ŒåŒ¹é…
	return s.performImmediateMatch(ctx, req, matchConfig)
}

// è®¡ç®—ç”¨æˆ·é€‰æ‹©çš„å»¶è¿Ÿæ—¶é—´
func (s *UnifiedAIService) calculateUserDelay(delayOption string) int {
	switch delayOption {
	case "quick":
		// 1-10åˆ†é’Ÿéšæœºå»¶è¿Ÿ
		return rand.Intn(10) + 1
	case "normal":
		// 10-30åˆ†é’Ÿéšæœºå»¶è¿Ÿ
		return rand.Intn(21) + 10
	case "slow":
		// 30-60åˆ†é’Ÿéšæœºå»¶è¿Ÿ
		return rand.Intn(31) + 30
	default:
		// é»˜è®¤æ— å»¶è¿Ÿï¼ˆå‘åå…¼å®¹ï¼‰
		return 0
	}
}

// æ‰§è¡Œç«‹å³åŒ¹é…
func (s *UnifiedAIService) performImmediateMatch(ctx context.Context, req *models.AIMatchRequest, matchConfig *AIConfigData) (*models.AIMatchResponse, error) {
	// è°ƒç”¨åŸæœ‰çš„åŒ¹é…é€»è¾‘ï¼ˆç»§æ‰¿è‡ªEnhancedAIServiceï¼‰
	response, err := s.EnhancedAIService.MatchPenPal(ctx, req)
	if err != nil {
		return nil, err
	}

	// ä½¿ç”¨é…ç½®å¢å¼ºåŒ¹é…ç»“æœ
	if matchConfig != nil {
		response = s.enhanceMatchResult(response, matchConfig)
	}

	return response, nil
}

// åºåˆ—åŒ–åŒ¹é…è¯·æ±‚
func (s *UnifiedAIService) marshalMatchRequest(req *models.AIMatchRequest) string {
	data, _ := json.Marshal(req)
	return string(data)
}

// GetPersonaList è·å–å¯ç”¨äººè®¾åˆ—è¡¨ï¼ˆä»é…ç½®ï¼‰
func (s *UnifiedAIService) GetPersonaList() ([]models.AIPersonaInfo, error) {
	log.Println("ğŸ‘¥ [UnifiedAIService] è·å–äººè®¾åˆ—è¡¨")

	personas := []models.AIPersona{
		models.PersonaPoet, models.PersonaPhilosopher, models.PersonaArtist,
		models.PersonaScientist, models.PersonaTraveler, models.PersonaHistorian,
		models.PersonaMentor, models.PersonaFriend,
	}

	result := make([]models.AIPersonaInfo, 0, len(personas))

	for _, persona := range personas {
		personaConfig, err := s.configService.GetPersonaConfig(string(persona))
		if err != nil {
			// å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
			personaConfig = s.getDefaultPersonaConfig(persona)
		}

		info := models.AIPersonaInfo{
			ID:          string(persona),
			Name:        personaConfig.Name,
			Description: personaConfig.Description,
			Style:       personaConfig.Style,
			Available:   true,
		}

		result = append(result, info)
	}

	log.Printf("âœ… [UnifiedAIService] è¿”å› %d ä¸ªå¯ç”¨äººè®¾", len(result))
	return result, nil
}

// ä»é…ç½®è·å–çµæ„Ÿå†…å®¹
func (s *UnifiedAIService) getInspirationsFromConfig(req *models.AIInspirationRequest) ([]struct {
	ID     string   `json:"id"`
	Theme  string   `json:"theme"`
	Prompt string   `json:"prompt"`
	Style  string   `json:"style"`
	Tags   []string `json:"tags"`
}, error) {
	// æ£€æŸ¥ç¼“å­˜
	if s.isCacheValid() {
		if cached, exists := s.templateCache["inspiration"]; exists {
			return s.selectTemplatesFromCache(cached, req), nil
		}
	}

	// ä»é…ç½®æœåŠ¡è·å–æ¨¡æ¿
	templates, err := s.configService.GetTemplates("inspiration")
	if err != nil {
		return nil, err
	}

	// æ›´æ–°ç¼“å­˜
	s.templateCache["inspiration"] = templates
	s.cacheLastUpdated = time.Now()

	// æ ¹æ®è¯·æ±‚ç­›é€‰æ¨¡æ¿
	return s.selectTemplatesFromCache(templates, req), nil
}

// ä»ç¼“å­˜ä¸­é€‰æ‹©åˆé€‚çš„æ¨¡æ¿
func (s *UnifiedAIService) selectTemplatesFromCache(templates []models.AIContentTemplate, req *models.AIInspirationRequest) []struct {
	ID     string   `json:"id"`
	Theme  string   `json:"theme"`
	Prompt string   `json:"prompt"`
	Style  string   `json:"style"`
	Tags   []string `json:"tags"`
} {
	var selected []models.AIContentTemplate

	// å¦‚æœæŒ‡å®šäº†ä¸»é¢˜ï¼Œä¼˜å…ˆé€‰æ‹©åŒ¹é…çš„æ¨¡æ¿
	if req.Theme != "" {
		for _, template := range templates {
			if strings.Contains(template.Category, req.Theme) ||
				strings.Contains(template.Title, req.Theme) ||
				strings.Contains(template.Content, req.Theme) {
				selected = append(selected, template)
			}
		}
	}

	// å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ¨¡æ¿ï¼Œéšæœºé€‰æ‹©
	if len(selected) == 0 {
		selected = templates
	}

	// éšæœºæ‰“ä¹±é¡ºåº
	rand.Shuffle(len(selected), func(i, j int) {
		selected[i], selected[j] = selected[j], selected[i]
	})

	// é™åˆ¶æ•°é‡
	count := req.Count
	if count == 0 || count > 5 {
		count = 3
	}
	if len(selected) > count {
		selected = selected[:count]
	}

	// è½¬æ¢ä¸ºå“åº”æ ¼å¼
	result := make([]struct {
		ID     string   `json:"id"`
		Theme  string   `json:"theme"`
		Prompt string   `json:"prompt"`
		Style  string   `json:"style"`
		Tags   []string `json:"tags"`
	}, len(selected))

	for i, template := range selected {
		// æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
		go s.configService.UpdateTemplateUsage(template.ID)

		result[i] = struct {
			ID     string   `json:"id"`
			Theme  string   `json:"theme"`
			Prompt string   `json:"prompt"`
			Style  string   `json:"style"`
			Tags   []string `json:"tags"`
		}{
			ID:     template.ID,
			Theme:  template.Category,
			Prompt: template.Content,
			Style:  s.getTemplateStyle(template),
			Tags:   template.Tags,
		}
	}

	return result
}

// ç”ŸæˆAIè¡¥å……çµæ„Ÿ
func (s *UnifiedAIService) generateAIInspirations(ctx context.Context, req *models.AIInspirationRequest) ([]struct {
	ID     string   `json:"id"`
	Theme  string   `json:"theme"`
	Prompt string   `json:"prompt"`
	Style  string   `json:"style"`
	Tags   []string `json:"tags"`
}, error) {
	// è·å–AIç”Ÿæˆæç¤ºè¯é…ç½®
	systemPrompt, err := s.configService.GetSystemPrompt("inspiration")
	if err != nil {
		systemPrompt = s.getDefaultSystemPrompt("inspiration")
	}

	// æ„å»ºAIç”Ÿæˆæç¤º
	prompt := fmt.Sprintf("%s\n\nè¯·ä¸ºä¸»é¢˜'%s'ç”Ÿæˆä¸€æ¡å†™ä½œçµæ„Ÿã€‚è¦æ±‚ï¼šæ¸©æš–äººæ–‡ã€æ¿€å‘åˆ›ä½œã€å…·ä½“å¯æ“ä½œã€‚", 
		systemPrompt.Prompt, req.Theme)

	// è°ƒç”¨AIç”Ÿæˆ
	content, err := s.callAIProvider(ctx, prompt)
	if err != nil {
		return nil, err
	}

	// è§£æç”Ÿæˆçš„å†…å®¹
	inspiration := struct {
		ID     string   `json:"id"`
		Theme  string   `json:"theme"`
		Prompt string   `json:"prompt"`
		Style  string   `json:"style"`
		Tags   []string `json:"tags"`
	}{
		ID:     uuid.New().String(),
		Theme:  req.Theme,
		Prompt: content,
		Style:  "AIç”Ÿæˆ",
		Tags:   []string{"AIç”Ÿæˆ", req.Theme},
	}

	return []struct {
		ID     string   `json:"id"`
		Theme  string   `json:"theme"`
		Prompt string   `json:"prompt"`
		Style  string   `json:"style"`
		Tags   []string `json:"tags"`
	}{inspiration}, nil
}

// æ„å»ºå›ä¿¡æç¤ºè¯
func (s *UnifiedAIService) buildReplyPrompt(req *models.AIReplyRequest, personaConfig *PersonaConfig, systemPrompt *SystemPromptConfig) string {
	return fmt.Sprintf(`%s

äººè®¾è®¾å®šï¼š%s
å†™ä½œé£æ ¼ï¼š%s

åŸå§‹ä¿¡ä»¶ï¼š
æ ‡é¢˜ï¼š%s
å†…å®¹ï¼š%s

è¯·ä»¥è¿™ä¸ªäººè®¾çš„èº«ä»½ï¼Œå†™ä¸€å°æ¸©æš–è€ŒçœŸè¯šçš„å›ä¿¡ã€‚è¦æ±‚ï¼š
1. ä½“ç°äººè®¾ç‰¹è‰²å’Œé£æ ¼
2. é’ˆå¯¹åŸä¿¡ä»¶å†…å®¹è¿›è¡Œå›åº”
3. ä¿æŒæ¸©æš–äººæ–‡çš„è¯­æ°”
4. é•¿åº¦æ§åˆ¶åœ¨300-500å­—

å›ä¿¡å†…å®¹ï¼š`,
		systemPrompt.Prompt,
		personaConfig.Description,
		personaConfig.Style,
		req.OriginalLetter.Title,
		req.OriginalLetter.Content)
}

// ç”Ÿæˆå›ä¿¡æ ‡é¢˜
func (s *UnifiedAIService) generateReplyTitle(originalTitle string) string {
	if strings.HasPrefix(originalTitle, "Re: ") {
		return originalTitle
	}
	return fmt.Sprintf("Re: %s", originalTitle)
}

// å¢å¼ºåŒ¹é…ç»“æœ
func (s *UnifiedAIService) enhanceMatchResult(response *models.AIMatchResponse, matchConfig *AIConfigData) *models.AIMatchResponse {
	// è¿™é‡Œå¯ä»¥æ ¹æ®é…ç½®è°ƒæ•´åŒ¹é…ç®—æ³•çš„æƒé‡ã€è¯„åˆ†ç­‰
	// æš‚æ—¶è¿”å›åŸå§‹ç»“æœ
	return response
}

// è·å–é»˜è®¤äººè®¾é…ç½®
func (s *UnifiedAIService) getDefaultPersonaConfig(persona models.AIPersona) *PersonaConfig {
	defaultConfigs := map[models.AIPersona]*PersonaConfig{
		models.PersonaFriend: {
			Name:        "çŸ¥å¿ƒæœ‹å‹",
			Description: "æ¸©æš–è´´å¿ƒçš„å¥½æœ‹å‹ï¼Œæ€»æ˜¯æ„¿æ„å€¾å¬å’Œé™ªä¼´",
			Prompt:      "æˆ‘æ˜¯ä½ çš„çŸ¥å¿ƒæœ‹å‹ï¼Œæ€»æ˜¯æ„¿æ„å€¾å¬ä½ çš„å¿ƒå£°ã€‚æˆ‘ä¼šç”¨æœ€çœŸè¯šå’Œæ¸©æš–çš„æ€åº¦ä¸ä½ åˆ†äº«ç”Ÿæ´»ä¸­çš„ç‚¹ç‚¹æ»´æ»´ã€‚",
			Style:       "æ¸©æš–äº²åˆ‡",
		},
		models.PersonaMentor: {
			Name:        "äººç”Ÿå¯¼å¸ˆ",
			Description: "æ¸©å’Œç¿æ™ºçš„äººç”ŸæŒ‡å¯¼è€…ï¼Œä¹äºåˆ†äº«äººç”Ÿæ™ºæ…§å’Œç»éªŒ",
			Prompt:      "æˆ‘æ˜¯ä½ çš„äººç”Ÿå¯¼å¸ˆï¼Œæ‹¥æœ‰ä¸°å¯Œçš„äººç”Ÿé˜…å†ã€‚æˆ‘ä¼šç”¨æ¸©å’Œè€Œæ™ºæ…§çš„æ–¹å¼ä¸ºä½ ç­”ç–‘è§£æƒ‘ï¼Œåˆ†äº«äººç”Ÿçš„æ™ºæ…§ã€‚",
			Style:       "æ¸©å’Œæ™ºæ…§",
		},
	}

	if config, exists := defaultConfigs[persona]; exists {
		return config
	}

	// é»˜è®¤æœ‹å‹äººè®¾
	return defaultConfigs[models.PersonaFriend]
}

// è·å–é»˜è®¤ç³»ç»Ÿæç¤ºè¯
func (s *UnifiedAIService) getDefaultSystemPrompt(promptType string) *SystemPromptConfig {
	return &SystemPromptConfig{
		Prompt:        "ä½ æ˜¯OpenPenPalçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨æ¸©æš–å‹å¥½çš„è¯­æ°”å›åº”ç”¨æˆ·ã€‚",
		Temperature:   0.9,
		MaxTokens:     1000,
		ContextWindow: 4000,
		Guidelines:    []string{"ä¿æŒæ¸©æš–å‹å¥½", "é¿å…AIè…”è°ƒ"},
	}
}

// è·å–æ¨¡æ¿æ ·å¼
func (s *UnifiedAIService) getTemplateStyle(template models.AIContentTemplate) string {
	if style, exists := template.Metadata["style"]; exists {
		if styleStr, ok := style.(string); ok {
			return styleStr
		}
	}
	return template.Category
}

// æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
func (s *UnifiedAIService) isCacheValid() bool {
	return time.Since(s.cacheLastUpdated) < s.cacheTTL
}

// è°ƒç”¨AIæä¾›å•†ï¼ˆç»§æ‰¿è‡ªåŸæœ‰å®ç°ï¼‰
func (s *UnifiedAIService) callAIProvider(ctx context.Context, prompt string) (string, error) {
	// è·å–æ´»è·ƒçš„AIé…ç½®
	config, err := s.GetActiveProvider()
	if err != nil {
		return "", fmt.Errorf("è·å–AIé…ç½®å¤±è´¥: %w", err)
	}

	// è°ƒç”¨ç›¸åº”çš„AIæä¾›å•†
	return s.callAIAPI(ctx, config, prompt, models.TaskTypeReply)
}

// getFallbackInspiration ä¿ç•™åŸæœ‰çš„fallbackæœºåˆ¶
func (s *UnifiedAIService) getFallbackInspiration(req *models.AIInspirationRequest) *models.AIInspirationResponse {
	// è°ƒç”¨åŸæœ‰çš„generateLocalInspirationsæ–¹æ³•
	return s.AIService.generateLocalInspirations(req)
}